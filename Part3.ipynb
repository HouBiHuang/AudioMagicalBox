{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "300966cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\r6017\\AppData\\Local\\Temp\\tmp3nzah2ih\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\r6017\\AppData\\Local\\Temp\\tmp3nzah2ih\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "187824"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"將tensorflow檔轉成tensorflow lite，使機器負載量變小\"\"\"\n",
    "from tensorflow import lite\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# Parameters\n",
    "keras_model_filename = './h5/recording16.h5' #訓練好的模型\n",
    "tflite_filename = './tflite/recording16.tflite' #預建置檔案\n",
    "\n",
    "# Convert model to TF Lite model\n",
    "model = models.load_model(keras_model_filename) #載入本來的模型\n",
    "converter = lite.TFLiteConverter.from_keras_model(model) #將模型載入轉換器\n",
    "tflite_model = converter.convert() #進行轉換\n",
    "open(tflite_filename, 'wb').write(tflite_model) #輸出轉換後的模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18c0e06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "著\n",
      "MAX:0.8368101716041565\n",
      "0時0分3.4秒\n",
      "著\n",
      "MAX:0.7248403429985046\n",
      "0時0分4.1秒\n",
      "那\n",
      "MAX:0.438682496547699\n",
      "0時0分5.6秒\n",
      "著\n",
      "MAX:0.3334646224975586\n",
      "0時0分6.6秒\n",
      "著\n",
      "MAX:0.856688380241394\n",
      "0時0分8.5秒\n",
      "吼\n",
      "MAX:0.44731956720352173\n",
      "0時0分8.9秒\n",
      "著\n",
      "MAX:0.9233126044273376\n",
      "0時0分10.6秒\n",
      "著\n",
      "MAX:0.9887375831604004\n",
      "0時0分11.1秒\n",
      "著\n",
      "MAX:0.45876601338386536\n",
      "0時0分12.5秒\n",
      "著\n",
      "MAX:0.9717028737068176\n",
      "0時0分13.2秒\n",
      "吼\n",
      "MAX:0.5198924541473389\n",
      "0時0分14.0秒\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-61798417773b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     callback=sd_callback):\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melapsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#num_mfcc = 23，rec_duration = 0.5\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import python_speech_features\n",
    "import tensorflow as tf\n",
    "from PyQt5.QtCore import QTime\n",
    "import librosa\n",
    "#import RPi.GPIO as GPIO\n",
    "\n",
    "# Parameters\n",
    "debug_time = 0 #Debug用\n",
    "debug_acc = 1 #Debug用\n",
    "led_pin = 8 #LED PIN\n",
    "word_threshold = 0.5 #預測值>0.5，表示stop\n",
    "rec_duration = 0.5 #每一段錄音持續時間\n",
    "#window_stride = 0.5\n",
    "sample_rate = 48000 #取樣率(依MIC不同而改變)\n",
    "resample_rate = 8000 #重整後的取樣率(符合MODEL)\n",
    "num_channels = 1 #音訊深度\n",
    "num_mfcc = 23 #回傳mfcc的量\n",
    "model_path = './tflite/recording23.tflite'\n",
    "words = ['ㄏㄧㄡ', 'ㄟ', '吼', '啦', '嗯', '的一個', '的這個', '的那個', '著', '那', '那那個', '阿']#答案對應到的字詞\n",
    "\n",
    "s = 0 #秒\n",
    "m = 0 #分\n",
    "h = 0 #時\n",
    "\n",
    "# Sliding window\n",
    "window = np.zeros(int(rec_duration * resample_rate) * 2)#取樣音頻數據變數\n",
    "\n",
    "# GPIO \n",
    "#GPIO.setwarnings(False)\n",
    "#GPIO.setmode(GPIO.BOARD)\n",
    "#GPIO.setup(8, GPIO.OUT, initial=GPIO.LOW)\n",
    "\n",
    "# Load model (interpreter)\n",
    "interpreter = tf.lite.Interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "#開始計時\n",
    "counter = QTime()\n",
    "counter.restart()\n",
    "\n",
    "# Decimate (filter and downsample)\n",
    "def decimate(signal, old_fs, new_fs):\n",
    "    \n",
    "    #檢查是否降低音頻\n",
    "    if new_fs > old_fs:\n",
    "        print(\"Error: target sample rate higher than original\")\n",
    "        return signal, old_fs\n",
    "    \n",
    "    #檢查是否為整數(只能在整數下執行)\n",
    "    dec_factor = old_fs / new_fs\n",
    "    if not dec_factor.is_integer():\n",
    "        print(\"Error: can only decimate by integer factor\")\n",
    "        return signal, old_fs\n",
    "\n",
    "    # Do decimation\n",
    "    resampled_signal = scipy.signal.decimate(signal, int(dec_factor))\n",
    "    \n",
    "    return resampled_signal, new_fs\n",
    "\n",
    "# This gets called every 0.5 seconds\n",
    "def sd_callback(rec, frames, time, status):\n",
    "\n",
    "    #GPIO.output(led_pin, GPIO.LOW)\n",
    "    \n",
    "    # Notify if errors\n",
    "    if status:\n",
    "        print('Error:', status)\n",
    "    \n",
    "    # Remove 2nd dimension from recording sample\n",
    "    #壓縮成1D張量\n",
    "    rec = np.squeeze(rec)\n",
    "    \n",
    "    # Resample\n",
    "    #重取樣成8000HZ(以符合訓練模型)\n",
    "    rec, new_fs = decimate(rec, sample_rate, resample_rate)\n",
    "    \n",
    "    # Save recording onto sliding window\n",
    "    #將音訊輸入到window\n",
    "    window[:len(window)//2] = window[len(window)//2:]\n",
    "    window[len(window)//2:] = rec\n",
    "    \n",
    "    S = np.abs(librosa.stft(window)) #將整個window音訊做stft，並轉成絕對值\n",
    "    #print(\"np.sum(S):\" + str(np.sum(S)))\n",
    "    \n",
    "    if np.sum(S) > 3000: #判斷S的總和是否>3000，如果>3000，代表有講話\n",
    "        # Compute features\n",
    "        mfccs = python_speech_features.base.mfcc(window, #輸入訊號\n",
    "                                            samplerate=new_fs, #取樣率\n",
    "                                            winlen=0.256, #音框涵蓋時間\n",
    "                                            winstep=0.050, #音框間距離\n",
    "                                            numcep=num_mfcc, #返回係數的量\n",
    "                                            nfilt=26, #過濾器數量\n",
    "                                            nfft=2048,#FFT大小\n",
    "                                            preemph=0.0,#不用預強化濾波器\n",
    "                                            ceplifter=0,#ROBUST\n",
    "                                            appendEnergy=False,#係數0的話對被替代成總音框能量的對數\n",
    "                                            winfunc=np.hanning)#hanning window\n",
    "        mfccs = mfccs.transpose()\n",
    "        \n",
    "        # Make prediction from model\n",
    "        in_tensor = np.float32(mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1))\n",
    "        #設定輸入張量\n",
    "        interpreter.set_tensor(input_details[0]['index'], in_tensor)\n",
    "        #進行預測\n",
    "        interpreter.invoke()\n",
    "        #取得輸出張量\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        val = output_data[0]#取得預測值\n",
    "        val = val.tolist() #np.ndarray to list\n",
    "        list_val_max = max(val) #取得最大值\n",
    "        list_val_maxIndex = val.index(max(val)) #取得最大值的索引  \n",
    "        \n",
    "        if(list_val_max >= 0.3):#如果預測值>=0.3\n",
    "            print(words[list_val_maxIndex])#輸出相對應的字詞\n",
    "            print(\"MAX:\" + str(list_val_max))#輸出預測值當中最大的值\n",
    "            print(str(h) + \"時\" + str(m) + \"分\" + \"{:.1f}秒\".format(s))              \n",
    "    \n",
    "    \n",
    "# Start streaming from microphone\n",
    "with sd.InputStream(channels=num_channels,\n",
    "                    samplerate=sample_rate,\n",
    "                    blocksize=int(sample_rate * rec_duration),\n",
    "                    callback=sd_callback):\n",
    "    while True:\n",
    "        s = float(counter.elapsed() / 1000)\n",
    "        if(s >= 60):\n",
    "            counter.restart()\n",
    "            s = 0\n",
    "            m = m + 1\n",
    "        if(m == 60):\n",
    "            m = 0\n",
    "            h = h + 1\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688d835a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: input overflow\n",
      "Error: input overflow\n",
      "Error: input overflow\n",
      "Error: input overflow\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b9730dbe1de2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    131\u001b[0m                     callback=sd_callback):\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melapsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#num_mfcc = 23，rec_duration = 0.25\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import python_speech_features\n",
    "import tensorflow as tf\n",
    "from PyQt5.QtCore import QTime\n",
    "import librosa\n",
    "#import RPi.GPIO as GPIO\n",
    "\n",
    "# Parameters\n",
    "debug_time = 0 #Debug用\n",
    "debug_acc = 1 #Debug用\n",
    "led_pin = 8 #LED PIN\n",
    "word_threshold = 0.5 #預測值>0.5，表示stop\n",
    "rec_duration = 0.25 #每一段錄音持續時間\n",
    "#window_stride = 0.5\n",
    "sample_rate = 48000 #取樣率(依MIC不同而改變)\n",
    "resample_rate = 8000 #重整後的取樣率(符合MODEL)\n",
    "num_channels = 1 #音訊深度\n",
    "num_mfcc = 23 #回傳mfcc的量\n",
    "model_path = './tflite/recording23.tflite'\n",
    "words = ['ㄏㄧㄡ', 'ㄟ', '吼', '啦', '嗯', '的一個', '的這個', '的那個', '著', '那', '那那個', '阿']#答案對應到的字詞\n",
    "\n",
    "s = 0 #秒\n",
    "m = 0 #分\n",
    "h = 0 #時\n",
    "\n",
    "# Sliding window\n",
    "window = np.zeros(int(rec_duration * resample_rate) * 4)#取樣音頻數據變數\n",
    "\n",
    "# GPIO \n",
    "#GPIO.setwarnings(False)\n",
    "#GPIO.setmode(GPIO.BOARD)\n",
    "#GPIO.setup(8, GPIO.OUT, initial=GPIO.LOW)\n",
    "\n",
    "# Load model (interpreter)\n",
    "interpreter = tf.lite.Interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "#開始計時\n",
    "counter = QTime()\n",
    "counter.restart()\n",
    "\n",
    "# Decimate (filter and downsample)\n",
    "def decimate(signal, old_fs, new_fs):\n",
    "    \n",
    "    #檢查是否降低音頻\n",
    "    if new_fs > old_fs:\n",
    "        print(\"Error: target sample rate higher than original\")\n",
    "        return signal, old_fs\n",
    "    \n",
    "    #檢查是否為整數(只能在整數下執行)\n",
    "    dec_factor = old_fs / new_fs\n",
    "    if not dec_factor.is_integer():\n",
    "        print(\"Error: can only decimate by integer factor\")\n",
    "        return signal, old_fs\n",
    "\n",
    "    # Do decimation\n",
    "    resampled_signal = scipy.signal.decimate(signal, int(dec_factor))\n",
    "    \n",
    "    return resampled_signal, new_fs\n",
    "\n",
    "# This gets called every 0.5 seconds\n",
    "def sd_callback(rec, frames, time, status):\n",
    "\n",
    "    #GPIO.output(led_pin, GPIO.LOW)\n",
    "    \n",
    "    # Notify if errors\n",
    "    if status:\n",
    "        print('Error:', status)\n",
    "    \n",
    "    # Remove 2nd dimension from recording sample\n",
    "    #壓縮成1D張量\n",
    "    rec = np.squeeze(rec)\n",
    "    \n",
    "    # Resample\n",
    "    #重取樣成8000HZ(以符合訓練模型)\n",
    "    rec, new_fs = decimate(rec, sample_rate, resample_rate)\n",
    "    \n",
    "    # Save recording onto sliding window\n",
    "    #將音訊輸入到window\n",
    "    window[:2000] = window[2000:4000]\n",
    "    window[2000:4000] = window[4000:6000]\n",
    "    window[4000:6000] = window[6000:]\n",
    "    window[6000:] = rec\n",
    "    \n",
    "    S = np.abs(librosa.stft(window)) #將整個window音訊做stft，並轉成絕對值\n",
    "    #print(\"np.sum(S):\" + str(np.sum(S)))\n",
    "\n",
    "    if np.sum(S) > 3000: #判斷S的總和是否>3000，如果>3000，代表有講話\n",
    "        # Compute features\n",
    "        mfccs = python_speech_features.base.mfcc(window, #輸入訊號\n",
    "                                            samplerate=new_fs, #取樣率\n",
    "                                            winlen=0.256, #音框涵蓋時間\n",
    "                                            winstep=0.050, #音框間距離\n",
    "                                            numcep=num_mfcc, #返回係數的量\n",
    "                                            nfilt=26, #過濾器數量\n",
    "                                            nfft=2048,#FFT大小\n",
    "                                            preemph=0.0,#不用預強化濾波器\n",
    "                                            ceplifter=0,#ROBUST\n",
    "                                            appendEnergy=False,#係數0的話對被替代成總音框能量的對數\n",
    "                                            winfunc=np.hanning)#hanning window\n",
    "        mfccs = mfccs.transpose()\n",
    "        \n",
    "        # Make prediction from model\n",
    "        in_tensor = np.float32(mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1))\n",
    "        #設定輸入張量\n",
    "        interpreter.set_tensor(input_details[0]['index'], in_tensor)\n",
    "        #進行預測\n",
    "        interpreter.invoke()\n",
    "        #取得輸出張量\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        val = output_data[0]#取得預測值\n",
    "        val = val.tolist() #np.ndarray to list\n",
    "        list_val_max = max(val) #取得最大值\n",
    "        list_val_maxIndex = val.index(max(val)) #取得最大值的索引  \n",
    "        \n",
    "        if(list_val_max >= 0.3):#如果預測值>=0.3\n",
    "            print(words[list_val_maxIndex])#輸出相對應的字詞\n",
    "            print(\"MAX:\" + str(list_val_max))#輸出預測值當中最大的值\n",
    "            print(str(h) + \"時\" + str(m) + \"分\" + \"{:.1f}秒\".format(s))\n",
    "    \n",
    "# Start streaming from microphone\n",
    "with sd.InputStream(channels=num_channels,\n",
    "                    samplerate=sample_rate,\n",
    "                    blocksize=int(sample_rate * rec_duration),\n",
    "                    callback=sd_callback):\n",
    "    while True:\n",
    "        s = float(counter.elapsed() / 1000)\n",
    "        if(s >= 60):\n",
    "            counter.restart()\n",
    "            s = 0\n",
    "            m = m + 1\n",
    "        if(m == 60):\n",
    "            m = 0\n",
    "            h = h + 1\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654e090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
